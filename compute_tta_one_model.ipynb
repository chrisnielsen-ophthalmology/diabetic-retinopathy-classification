{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d70f8877",
   "metadata": {},
   "source": [
    "### The purpose of this script is the following:\n",
    "\n",
    "1. Pick the model epoch with the best performing kappa score\n",
    "2. Use d4_transform for TTA which consists of a horizontal flip and 4 different 90 degree rotations. To aggregate the results, I selected the mean of the prediction scores\n",
    "3. Compute the kappa score when using TTA and not TTA and compare the results\n",
    "\n",
    "<br>\n",
    "\n",
    "Results:\n",
    "* TTA did improve the performance for the B3 model: \n",
    "    * QuadraticWeightedKappa (Non-TTA): 0.7974120604486354\n",
    "    * QuadraticWeightedKappa (TTA): 0.8016524965905782\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a71e685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f30e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dd8aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d5752fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import os\n",
    "import config\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from dataset import DRDataset\n",
    "from torchvision.utils import save_image\n",
    "from torchsummary import summary\n",
    "from utils import (\n",
    "    B3Config,\n",
    "    B4Config,\n",
    "    B5Config,\n",
    "    load_checkpoint,\n",
    "    save_checkpoint,\n",
    "    check_accuracy,\n",
    "    make_prediction,\n",
    "    get_csv_for_blend,\n",
    ")\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ttach as tta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2a9aab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca36a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af7679f2",
   "metadata": {},
   "source": [
    "### Code to output predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc50662",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_prediction(model, loader, output_csv=\"submission.csv\"):\n",
    "    preds = []\n",
    "    filenames = []\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    for x, y, files in tqdm(loader):\n",
    "        x = x.to(config.DEVICE)\n",
    "        with torch.no_grad():\n",
    "            predictions = model(x)\n",
    "            # Convert MSE floats to integer predictions\n",
    "            predictions[predictions < 0.5] = 0\n",
    "            predictions[(predictions >= 0.5) & (predictions < 1.5)] = 1\n",
    "            predictions[(predictions >= 1.5) & (predictions < 2.5)] = 2\n",
    "            predictions[(predictions >= 2.5) & (predictions < 3.5)] = 3\n",
    "            predictions[(predictions >= 3.5) & (predictions < 10000000)] = 4\n",
    "            predictions = predictions.long().squeeze(1)\n",
    "            preds.append(predictions.cpu().numpy())\n",
    "\n",
    "            all_preds.append(predictions.detach().cpu().numpy())\n",
    "            all_labels.append(y.detach().cpu().numpy())\n",
    "            filenames += files\n",
    "\n",
    "    df = pd.DataFrame({\"image\": filenames, \"level\": np.concatenate(preds, axis=0)})\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    model.train()\n",
    "    print(\"Done with predictions\")\n",
    "    return (np.concatenate(all_preds, axis=0, dtype=np.int64), np.concatenate(all_labels, axis=0, dtype=np.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2334b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcda33b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84514b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf209ecd",
   "metadata": {},
   "source": [
    "### Determine best model (for this code only pick 1 of the models to test TTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da8ea057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b3\n",
      "loading efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "load model\n",
      "=> Loading checkpoint\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_checkpoint_path = 'C:/GitHub/chrisnielsen-ophthalmology/diabetic-retinopathy-classification/DiabeticRetinopathy/models'\n",
    "results_output_path = 'C:/GitHub/chrisnielsen-ophthalmology/diabetic-retinopathy-classification/DiabeticRetinopathy/results'\n",
    "existing_result_files = [f for f in listdir(results_output_path) if isfile(join(results_output_path, f))]\n",
    "\n",
    "\n",
    "model_config_dict = {'b3': B3Config(),\n",
    "                     'b4': B4Config(),\n",
    "                     'b5': B5Config()}\n",
    "\n",
    "\n",
    "for model_type in ['b3','b4','b5']:\n",
    "    print(model_type)\n",
    "    model_config = model_config_dict[model_type]\n",
    "\n",
    "    for ensemble_iter in range(model_config.number_of_ensemble_iters):\n",
    "        model_output_log_name = model_type + '_' + str(ensemble_iter) + '.csv'\n",
    "        if model_output_log_name in existing_result_files:\n",
    "            results_df = pd.read_csv(results_output_path + '/' + model_output_log_name)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        best_performing_model_epoch = results_df.kappa.argmax()\n",
    "        \n",
    "        \n",
    "        val_ds = DRDataset(\n",
    "                images_folder=\"C:/Data/Kaggle EyePACS/test_images_resized_512/\",\n",
    "                path_to_csv=\"C:/Data/Kaggle EyePACS/test_public.csv\",\n",
    "                transform=model_config.val_transforms,\n",
    "            )\n",
    "        \n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            val_ds,\n",
    "            batch_size=model_config.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=12, persistent_workers=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        loss_fn = nn.MSELoss()\n",
    "\n",
    "        print('loading', model_config.model_name)\n",
    "        model = EfficientNet.from_pretrained(model_config.model_name)\n",
    "        model._fc = nn.Linear(model_config.fc_size, 1)\n",
    "        model = model.to(config.DEVICE)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY)\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "\n",
    "        print('load model')\n",
    "        model_path = model_checkpoint_path + '/' + model_type + '_' + str(ensemble_iter) + '_' + str(best_performing_model_epoch) + \".pth.tar\"\n",
    "        load_checkpoint(torch.load(model_path), model, optimizer, config.LEARNING_RATE)\n",
    "        \n",
    "\n",
    "        break\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7c1f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4278bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62ef55cf",
   "metadata": {},
   "source": [
    "### Compute non-TTA predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0892436e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 455/455 [01:08<00:00,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds, labels = make_prediction(model, val_loader, \"predictions/submission_.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a3e2f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "555c35a0",
   "metadata": {},
   "source": [
    "### Compute TTA predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdb8070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tta_model = tta.ClassificationTTAWrapper(model, tta.aliases.d4_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07f4e715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 455/455 [07:17<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds_tta, labels_tta = make_prediction(tta_model, val_loader, \"predictions/submission_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aef9d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a3835b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96ccb1c2",
   "metadata": {},
   "source": [
    "### Compute weighted kappa results for non-TTA and TTA predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "526e3b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuadraticWeightedKappa (Non-TTA): 0.7974120604486354\n",
      "QuadraticWeightedKappa (TTA): 0.8016524965905782\n"
     ]
    }
   ],
   "source": [
    "print(f\"QuadraticWeightedKappa (Non-TTA): {cohen_kappa_score(labels, preds, weights='quadratic')}\")\n",
    "print(f\"QuadraticWeightedKappa (TTA): {cohen_kappa_score(labels_tta, preds_tta, weights='quadratic')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d263688f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
